{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Hacker News Posts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing Hacker News data in determining the likelihood of a post having solid engagements with audiences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm doing a series of things here:\n",
    "* Open `HNpost` file. \n",
    "* Read and convert the read file into a list of lists\n",
    "* Remove the header row \n",
    "* Assign the rest of the list into a variable named `hndata`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "opened_file = open(\"/storage/emulated/0/Python Worksheet/HNposts.csv\") \n",
    "read_file = reader(opened_file)\n",
    "hndata = list(read_file)\n",
    "header = hndata[0]\n",
    "hndata = hndata[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have the file opened and converted to a list of lists, I can begin by performing some basic operations on it. How about exploring the data for now üíÅüèΩ‚Äç‚ôÇÔ∏è?\n",
    "\n",
    "This is what I'm going to doüëåüèΩ:\n",
    "* I will write a function that can explore, not just the `HNposts` dataset, but any dataset within defined limits (provided the data has been opened and converted into a list of list by the function above).\n",
    "* I will provide in the function a system that will‚Äîin addition to exploring the data between any defined limits‚Äîallow us to know how many rows and columns we have in the dataset. This is important as it makes us aware of exactly how big the data we are dealing with isüëåüèΩ. \n",
    "\n",
    "Get itü§∑üèΩ‚Äç‚ôÇÔ∏è? Cute thenüëäüèΩ. Now let's goüí™üèΩ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def explore_data(dataset, start, end, rows_and_columns = False) :\n",
    "    display = dataset[start:end]\n",
    "    for row in display:\n",
    "        print (row)\n",
    "        print ('\\n') \n",
    "    \n",
    "    if rows_and_columns:\n",
    "        print ('There are {0} number of rows'.format(len(dataset))) \n",
    "        print ('There are {0} number of columns'.format(len(dataset[0]))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try out our function to see if it works. We have to make sure there ain't no bugs and glitches here people üòâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explore_data(hndata, 0, 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See? It worksüòÑ. Now let's focus. Notice that in arguments supplied in the function, we have a particular one: `rows_and_columns = False?` That is what I mentioned earlier at play. You see, the default argument there is `False` which means it is not necessary we display the number of rows and columns if we don't want to. \n",
    "\n",
    "However, if we have performed some cleaning on our data, and we want to know the number of rows that we are left with, that particular argument will come in handy. And all we have to do then is simply set it as `True` whenever we are giving our arguments alongside the updated dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm specifically interested in posts whose titles begin with either `Ask HN` or `Show HN`. Users submit Ask HN posts to ask the Hacker News community a specific question.\n",
    "\n",
    "\n",
    "Then we are going to compare these two types of posts to determine the following:\n",
    "* Do Ask HN or Show HN receive more comments on average?\n",
    "* Do posts created at a certain time receive more comments on average?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm going to a particular method to separate posts beginning with Ask HN and Show HN into two different lists next.\n",
    "\n",
    "Follow along üòâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_posts = [] \n",
    "show_posts = [] \n",
    "other_posts = [] \n",
    "for row in hndata:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now check if we have some values in our created lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9139\n",
      "10158\n"
     ]
    }
   ],
   "source": [
    "print (len(ask_posts)) \n",
    "print (len(show_posts)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output we have, it is clear we already have some values in our lists. We can further crosscheck this by printing out some few rows from our lists. You could do that if you have the time, but as pertinent to what I want to achieve here, it means you will sleep there doing it alone üòÑ. \n",
    "\n",
    "So, we locomote üí™üèΩ. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n"
     ]
    }
   ],
   "source": [
    "print (header) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_comments = []\n",
    "for row in ask_posts:\n",
    "    comments_num = int(row[4])\n",
    "    ask_comments.append(comments_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The body of codes in the cell above basically does one job:\n",
    "* Collect all the comments from the `Ask HN` posts and store them into a separate list. \n",
    "\n",
    "Don't forget that our aim is to calculate the average of these comments. Yet, we locomote üöô. \n",
    "\n",
    "\n",
    "Now let's find the average for these figures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.393478498741656\n"
     ]
    }
   ],
   "source": [
    "average_ask_commments = sum(ask_comments)/len(ask_posts)\n",
    "print (average_ask_commments) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the same procedure to find the average of the `Show HN` posts. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.886099625910612\n"
     ]
    }
   ],
   "source": [
    "show_comments = []\n",
    "for row in show_posts:\n",
    "    comments_num = int(row[4])\n",
    "    show_comments.append(comments_num)\n",
    "\n",
    "average_show_commments = sum(show_comments)/len(show_posts)\n",
    "print (average_show_commments) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our last two code cells, we have outputs `10.39` and `4.89` for average number of `Ask HN` and `Show HN` posts respectively.\n",
    "\n",
    "Which means that `Ask HN` posts on Hacker News posts received more engagements than `Show HN` posts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to determine if `Ask HN` posts created at a certain time are nor likely to attract comments. \n",
    "\n",
    "We can do this by generating a frequency table for ask posts by hour and find the total comments on all the posts at that hour. \n",
    "\n",
    "\n",
    "Let's attempt this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12578908', 'Ask HN: What TLD do you use for local development?', '', '4', '7', 'Sevrene', '9/26/2016 2:53'], ['12578522', 'Ask HN: How do you pass on your work when you die?', '', '6', '3', 'PascLeRasc', '9/26/2016 1:17']]\n"
     ]
    }
   ],
   "source": [
    "print (ask_posts[:2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "import datetime as dt\n",
    "for row in ask_posts:\n",
    "    datetime = row[6]\n",
    "    comments = int(row[4]) \n",
    "    datetime = dt.datetime.strptime(datetime,\"%m/%d/%Y %H:%M\")\n",
    "    hour = datetime.strftime(\"%H\") \n",
    "    if hour not in posts_by_hour:\n",
    "        posts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = comments\n",
    "    else:\n",
    "        posts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'02': 269, '01': 282, '22': 383, '21': 518, '19': 552, '17': 587, '15': 646, '14': 513, '13': 444, '11': 312, '10': 282, '09': 222, '07': 226, '03': 271, '23': 343, '20': 510, '16': 579, '08': 257, '00': 301, '18': 614, '12': 342, '04': 243, '06': 234, '05': 209}\n"
     ]
    }
   ],
   "source": [
    "print (posts_by_hour) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'02': 2996, '01': 2089, '22': 3372, '21': 4500, '19': 3954, '17': 5547, '15': 18525, '14': 4972, '13': 7245, '11': 2797, '10': 3013, '09': 1477, '07': 1585, '03': 2154, '23': 2297, '20': 4462, '16': 4466, '08': 2362, '00': 2277, '18': 4877, '12': 4234, '04': 2360, '06': 1587, '05': 1838}\n"
     ]
    }
   ],
   "source": [
    "print (comments_by_hour) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the two outputs we have above, we can further calculate the average number of comments on ask posts made at a particular hour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_comments_by_hour = []\n",
    "for value in posts_by_hour:\n",
    "    if value in comments_by_hour:\n",
    "        average = comments_by_hour[value]/posts_by_hour[value]\n",
    "    avg_comments_by_hour.append([value, average]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['02', 11.137546468401487], ['01', 7.407801418439717], ['22', 8.804177545691905], ['21', 8.687258687258687], ['19', 7.163043478260869], ['17', 9.449744463373083], ['15', 28.676470588235293], ['14', 9.692007797270955], ['13', 16.31756756756757], ['11', 8.96474358974359], ['10', 10.684397163120567], ['09', 6.653153153153153], ['07', 7.013274336283186], ['03', 7.948339483394834], ['23', 6.696793002915452], ['20', 8.749019607843136], ['16', 7.713298791018998], ['08', 9.190661478599221], ['00', 7.5647840531561465], ['18', 7.94299674267101], ['12', 12.380116959064328], ['04', 9.7119341563786], ['06', 6.782051282051282], ['05', 8.794258373205741]]\n"
     ]
    }
   ],
   "source": [
    "print (avg_comments_by_hour) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we now have the results we need, this format makes it hard to identify the hours with the highest values. Let's finish by sorting the list of lists and printing the five highest values in a format that's easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.137546468401487, '02'], [7.407801418439717, '01'], [8.804177545691905, '22'], [8.687258687258687, '21'], [7.163043478260869, '19'], [9.449744463373083, '17'], [28.676470588235293, '15'], [9.692007797270955, '14'], [16.31756756756757, '13'], [8.96474358974359, '11'], [10.684397163120567, '10'], [6.653153153153153, '09'], [7.013274336283186, '07'], [7.948339483394834, '03'], [6.696793002915452, '23'], [8.749019607843136, '20'], [7.713298791018998, '16'], [9.190661478599221, '08'], [7.5647840531561465, '00'], [7.94299674267101, '18'], [12.380116959064328, '12'], [9.7119341563786, '04'], [6.782051282051282, '06'], [8.794258373205741, '05']]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_comments_by_hour = []\n",
    "for row in avg_comments_by_hour:\n",
    "    swap_avg_comments_by_hour.append([row[1], row[0]])\n",
    "print (swap_avg_comments_by_hour) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28.676470588235293, '15'], [16.31756756756757, '13'], [12.380116959064328, '12'], [11.137546468401487, '02'], [10.684397163120567, '10'], [9.7119341563786, '04'], [9.692007797270955, '14'], [9.449744463373083, '17'], [9.190661478599221, '08'], [8.96474358974359, '11'], [8.804177545691905, '22'], [8.794258373205741, '05'], [8.749019607843136, '20'], [8.687258687258687, '21'], [7.948339483394834, '03'], [7.94299674267101, '18'], [7.713298791018998, '16'], [7.5647840531561465, '00'], [7.407801418439717, '01'], [7.163043478260869, '19'], [7.013274336283186, '07'], [6.782051282051282, '06'], [6.696793002915452, '23'], [6.653153153153153, '09']]\n"
     ]
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_avg_comments_by_hour, reverse = True)\n",
    "print (sorted_swap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28.676470588235293, '15'], [16.31756756756757, '13'], [12.380116959064328, '12'], [11.137546468401487, '02'], [10.684397163120567, '10']]\n"
     ]
    }
   ],
   "source": [
    "top_5 = (sorted_swap[:5])\n",
    "print (top_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:00\n"
     ]
    }
   ],
   "source": [
    "hour = \"15\"\n",
    "hour = dt.datetime.strptime(hour, \"%H\")\n",
    "hour = hour.strftime(\"%H:%M\")\n",
    "print (hour) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:00: 28.68 comments per posts\n",
      "\n",
      "\n",
      "13:00: 16.32 comments per posts\n",
      "\n",
      "\n",
      "12:00: 12.38 comments per posts\n",
      "\n",
      "\n",
      "02:00: 11.14 comments per posts\n",
      "\n",
      "\n",
      "10:00: 10.68 comments per posts\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in top_5:\n",
    "    hour = row[1]\n",
    "    hour = dt.datetime.strptime(hour, \"%H\") \n",
    "    hour = hour.strftime(\"%H:%M\") \n",
    "    print (\"{0}: {1:.2f} comments per posts\".format(hour, row[0]))\n",
    "    print (\"\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output we have, we can infer that to have the best chance of getting more comments on posts, it should be created at `15:00` or `3 p.m`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
